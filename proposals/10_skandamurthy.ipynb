{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>I use pandas when it comes to Data Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Somerville_High_School_YRBS_Raw_Data_2002-2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Its better to have some basic data like length of Dataset etc.\n",
    "    First we have to see how many rows we have in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8871"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Now Rows and their dataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colomn_names = data.columns.to_series().groupby(data.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['year'], dtype='object'),\n",
       " dtype('float64'): Index(['cig_get', 'inha_age', 'inha_30', 'oxy_age', 'oxy_30', 'rx_high',\n",
       "        'rsk_pott', 'forced', 'tv_room', 'exer_7', 'thr_skl', 'thr_out', 'cope',\n",
       "        'control', 'exer_30', 'less_30', 'light_7', 'past60mn', 'typ60mn',\n",
       "        'aft_play', 'aft_park', 'aft_yard', 'aft_fiel', 'aft_cntr', 'aft_path',\n",
       "        'aft_prog', 'enc_aft', 'enc_gym', 'enc_rec', 'enc_home', 'enc_skl',\n",
       "        'drunk_30', 'family', 'children', 'resolve', 'manage', 'inj_fit',\n",
       "        'tense', 'heartrac', 'soc_fear', 'repeat', 'fear', 'cigarage',\n",
       "        'chew_age', 'fr_smok', 'fr_alc', 'fr_pot', 'fr_oth', 'talk_sex',\n",
       "        'study_7', 'read_7', 'work_7', 'stren_7'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['survey', 'id', 'age', 'gender', 'grade', 'race', 'language', 'live_us',\n",
       "        'parents', 'home',\n",
       "        ...\n",
       "        'sports', 'music', 'stu_gov', 'com_ser', 'com_groups', 'hrs_work',\n",
       "        'transskl', 'rx_use2', 'SCHOOL', 'SURLANG'],\n",
       "       dtype='object', length=167)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Colomn_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 1: Is there data missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Yes, Absolutely.It's a basic issue we face with basically any real time data. The below series shows the list of all colomn names and missing value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.05667763840793"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cells = np.product(data.shape)\n",
    "total_missing_values = data.isnull().sum().sum()\n",
    "\n",
    "percentage_of_data_missing = (total_missing_values/total_cells) *100\n",
    "percentage_of_data_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>As we see, there's 33% of data missing,Lets go a bit deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey          0\n",
      "id           1466\n",
      "age             0\n",
      "gender          0\n",
      "grade           0\n",
      "race            0\n",
      "language        0\n",
      "live_us         0\n",
      "parents         0\n",
      "home            0\n",
      "skl_gra         0\n",
      "fut_ed          0\n",
      "DOCT_12         0\n",
      "DENT_12         0\n",
      "witness         0\n",
      "emo_abus        0\n",
      "mistreat        0\n",
      "harassed        0\n",
      "hurtdate        0\n",
      "gang            0\n",
      "bull_skl        0\n",
      "nothing         0\n",
      "trystop         0\n",
      "teltea          0\n",
      "telpar          0\n",
      "telfri          0\n",
      "saw_bul         0\n",
      "tookpart        0\n",
      "justsaw         0\n",
      "intervene       0\n",
      "             ... \n",
      "aft_cntr     8871\n",
      "aft_path     8871\n",
      "aft_prog     8871\n",
      "enc_aft      8871\n",
      "enc_gym      8871\n",
      "enc_rec      8871\n",
      "enc_home     8871\n",
      "enc_skl      8871\n",
      "drunk_30     8871\n",
      "family       8871\n",
      "children     8871\n",
      "resolve      8871\n",
      "manage       8871\n",
      "inj_fit      8871\n",
      "tense        8871\n",
      "heartrac     8871\n",
      "soc_fear     8871\n",
      "repeat       8871\n",
      "fear         8871\n",
      "cigarage     8871\n",
      "chew_age     8871\n",
      "fr_smok      8871\n",
      "fr_alc       8871\n",
      "fr_pot       8871\n",
      "fr_oth       8871\n",
      "talk_sex     8871\n",
      "study_7      8871\n",
      "read_7       8871\n",
      "work_7       8871\n",
      "stren_7      8871\n",
      "Length: 221, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>As we can see,many rows contain zero info. We can find out colomns which contain zero data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Method 1 - Take the above series and loop it checking value == 8871\n",
    "(Number of rows in the dataset. Its actually 8872 but the counts start from 0 so value is down by 1)\n",
    "For now printing number of colomns with no values\n",
    "\"\"\"\n",
    "indexes = data.isnull().sum()\n",
    "num = 1\n",
    "for index,value in indexes.items():\n",
    "    if value == 8871:\n",
    "#        print(index)\n",
    "        num +=1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'cig_get', 'inha_age', 'inha_30', 'oxy_age', 'oxy_30', 'rx_high',\n",
      "       'rsk_pott', 'forced', 'tv_room', 'exer_7', 'thr_skl', 'thr_out', 'cope',\n",
      "       'control', 'exer_30', 'less_30', 'light_7', 'past60mn', 'typ60mn',\n",
      "       'aft_play', 'aft_park', 'aft_yard', 'aft_fiel', 'aft_cntr', 'aft_path',\n",
      "       'aft_prog', 'enc_aft', 'enc_gym', 'enc_rec', 'enc_home', 'enc_skl',\n",
      "       'drunk_30', 'family', 'children', 'resolve', 'manage', 'inj_fit',\n",
      "       'tense', 'heartrac', 'soc_fear', 'repeat', 'fear', 'cigarage',\n",
      "       'chew_age', 'fr_smok', 'fr_alc', 'fr_pot', 'fr_oth', 'talk_sex',\n",
      "       'study_7', 'read_7', 'work_7', 'stren_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Method 2 \n",
    "null_columns=data.columns[data.isnull().any()]\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> All the colomn names mentioned are having NaN in their entire colomns. We can do same thing to find the polar opposite in method one- find colomns with no values missing. Best way for now(without digging much into the datatype of colomn values,fill it with \"Nan\") and drop colomns which have no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(null_columns,axis=1)\n",
    "data= data.replace(r'^\\s+$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>race</th>\n",
       "      <th>language</th>\n",
       "      <th>live_us</th>\n",
       "      <th>parents</th>\n",
       "      <th>home</th>\n",
       "      <th>skl_gra</th>\n",
       "      <th>...</th>\n",
       "      <th>music</th>\n",
       "      <th>stu_gov</th>\n",
       "      <th>com_ser</th>\n",
       "      <th>com_groups</th>\n",
       "      <th>hrs_work</th>\n",
       "      <th>transskl</th>\n",
       "      <th>rx_use2</th>\n",
       "      <th>SCHOOL</th>\n",
       "      <th>SURLANG</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>SH10</td>\n",
       "      <td>18 years old or older</td>\n",
       "      <td>Male</td>\n",
       "      <td>Junior - 11th</td>\n",
       "      <td>Other</td>\n",
       "      <td>Another language</td>\n",
       "      <td>I have always lived in the United States</td>\n",
       "      <td>My mother and my father</td>\n",
       "      <td>A house/condo/apartment owned/rented by my par...</td>\n",
       "      <td>Mostly B's</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>SH10</td>\n",
       "      <td>17 years old</td>\n",
       "      <td>Male</td>\n",
       "      <td>Junior - 11th</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>More than 6 years, but not my whole life</td>\n",
       "      <td>My mother and a step-parent</td>\n",
       "      <td>A house/condo/apartment owned/rented by my par...</td>\n",
       "      <td>Mostly D's</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Get a ride</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survey                    age gender          grade                race  \\\n",
       "3660   SH10  18 years old or older   Male  Junior - 11th               Other   \n",
       "3706   SH10           17 years old   Male  Junior - 11th  Hispanic or Latino   \n",
       "\n",
       "              language                                   live_us  \\\n",
       "3660  Another language  I have always lived in the United States   \n",
       "3706           Spanish  More than 6 years, but not my whole life   \n",
       "\n",
       "                          parents  \\\n",
       "3660      My mother and my father   \n",
       "3706  My mother and a step-parent   \n",
       "\n",
       "                                                   home     skl_gra  ...   \\\n",
       "3660  A house/condo/apartment owned/rented by my par...  Mostly B's  ...    \n",
       "3706  A house/condo/apartment owned/rented by my par...  Mostly D's  ...    \n",
       "\n",
       "     music stu_gov com_ser com_groups hrs_work    transskl rx_use2 SCHOOL  \\\n",
       "3660    No      No      No        NaN     None        Walk     NaN    NaN   \n",
       "3706    No      No      No        NaN     None  Get a ride     NaN    NaN   \n",
       "\n",
       "     SURLANG  year  \n",
       "3660     NaN  2010  \n",
       "3706     NaN  2010  \n",
       "\n",
       "[2 rows x 167 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question 2: Is the data consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> I think data is consistent.To check data to be consistent,\n",
    "         check for duplicate entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8871\n"
     ]
    }
   ],
   "source": [
    "data[data.duplicated(keep=False)]\n",
    "print(len(data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> As we can see, there aren't any duplicates hence its consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question 3 : Is the data bugs free?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> What i understand of \"bug\" in data is data collected isn't proper.For instance the 'Id' and 'survey' field are inter-related. but there are many rows where neither of them are given. Assuming that both colomns are needed, Its a problem to figure out what/how to fill those places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> As per data itself, we can't feed it to any machine learning algorithms. As the data contains many categorical colomns, we can see for any \"outliers\" in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parents\n",
       "Another relative (like a grandparent, aunt/uncle)     226\n",
       "Foster parent(s)                                       16\n",
       "My father and a step-parent                            76\n",
       "My father only                                        152\n",
       "My mother and a step-parent                           389\n",
       "My mother and my father                              2873\n",
       "My mother only                                       1130\n",
       "Someone else not on this list                          92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('parents').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Summing up all the entries, It has nearly half of the entry missing!. Assuming that problem solved, the data is heavly biased to one catagory. Data isnt spread evenly.If this is a training-dataset and If this colomn was my label/target/prediction/output of the model, the output will be biased to one outcome itself as dataset itself has biased targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>If this imbalance is neglected, then we can say the entries which have negligible contributions considered as outliers which throws off the accuracy of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Conclusion</h3>\n",
    "1. If Data is missing, find a way to re-fill it or drop the colomn. \n",
    "2. If Data is having repeated entries, remove them.\n",
    "3. if Data has multiple colomns with contiuous values, try to get them under a standard scale and normalize the data if needed\n",
    "4. If Data is imbalanced,due to a particular colomn , try alternate ways to balance it our drop the colomn.\n",
    "\n",
    "\n",
    "All the above mentioned steps wil improve the integrity of the dataset. This pre-processing is required for all data and the process of doing it depends on the data. Hope I have answered the question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
