{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>I use pandas when it comes to Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Somerville_High_School_YRBS_Raw_Data_2002-2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Its better to have some basic data like length of Dataset etc.\n",
    "    First we have to see how many rows we have in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Now Rows and their dataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8871 entries, 0 to 8870\n",
      "Columns: 221 entries, survey to stren_7\n",
      "dtypes: float64(53), int64(1), object(167)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are way too many colomns just to derive an insight using a single command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colomn_names = data.columns.to_series().groupby(data.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['year'], dtype='object'),\n",
       " dtype('float64'): Index(['cig_get', 'inha_age', 'inha_30', 'oxy_age', 'oxy_30', 'rx_high',\n",
       "        'rsk_pott', 'forced', 'tv_room', 'exer_7', 'thr_skl', 'thr_out', 'cope',\n",
       "        'control', 'exer_30', 'less_30', 'light_7', 'past60mn', 'typ60mn',\n",
       "        'aft_play', 'aft_park', 'aft_yard', 'aft_fiel', 'aft_cntr', 'aft_path',\n",
       "        'aft_prog', 'enc_aft', 'enc_gym', 'enc_rec', 'enc_home', 'enc_skl',\n",
       "        'drunk_30', 'family', 'children', 'resolve', 'manage', 'inj_fit',\n",
       "        'tense', 'heartrac', 'soc_fear', 'repeat', 'fear', 'cigarage',\n",
       "        'chew_age', 'fr_smok', 'fr_alc', 'fr_pot', 'fr_oth', 'talk_sex',\n",
       "        'study_7', 'read_7', 'work_7', 'stren_7'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['survey', 'id', 'age', 'gender', 'grade', 'race', 'language', 'live_us',\n",
       "        'parents', 'home',\n",
       "        ...\n",
       "        'sports', 'music', 'stu_gov', 'com_ser', 'com_groups', 'hrs_work',\n",
       "        'transskl', 'rx_use2', 'SCHOOL', 'SURLANG'],\n",
       "       dtype='object', length=167)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Colomn_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 1: Is there data missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Yes, Absolutely.It's a basic issue we face with basically any real time data. The below series shows the list of all colomn names and missing value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.05667763840793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cells = np.product(data.shape)\n",
    "total_missing_values = data.isnull().sum().sum()\n",
    "\n",
    "percentage_of_data_missing = (total_missing_values/total_cells) *100\n",
    "percentage_of_data_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>As we see, there's 24% of data missing,Lets go a bit deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey          0\n",
      "id           1466\n",
      "age             0\n",
      "gender          0\n",
      "grade           0\n",
      "race            0\n",
      "language        0\n",
      "live_us         0\n",
      "parents         0\n",
      "home            0\n",
      "skl_gra         0\n",
      "fut_ed          0\n",
      "DOCT_12         0\n",
      "DENT_12         0\n",
      "witness         0\n",
      "emo_abus        0\n",
      "mistreat        0\n",
      "harassed        0\n",
      "hurtdate        0\n",
      "gang            0\n",
      "bull_skl        0\n",
      "nothing         0\n",
      "trystop         0\n",
      "teltea          0\n",
      "telpar          0\n",
      "telfri          0\n",
      "saw_bul         0\n",
      "tookpart        0\n",
      "justsaw         0\n",
      "intervene       0\n",
      "             ... \n",
      "aft_cntr     8871\n",
      "aft_path     8871\n",
      "aft_prog     8871\n",
      "enc_aft      8871\n",
      "enc_gym      8871\n",
      "enc_rec      8871\n",
      "enc_home     8871\n",
      "enc_skl      8871\n",
      "drunk_30     8871\n",
      "family       8871\n",
      "children     8871\n",
      "resolve      8871\n",
      "manage       8871\n",
      "inj_fit      8871\n",
      "tense        8871\n",
      "heartrac     8871\n",
      "soc_fear     8871\n",
      "repeat       8871\n",
      "fear         8871\n",
      "cigarage     8871\n",
      "chew_age     8871\n",
      "fr_smok      8871\n",
      "fr_alc       8871\n",
      "fr_pot       8871\n",
      "fr_oth       8871\n",
      "talk_sex     8871\n",
      "study_7      8871\n",
      "read_7       8871\n",
      "work_7       8871\n",
      "stren_7      8871\n",
      "Length: 221, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see,many rows contain zero info. We can find out colomns which contain zero data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Method 1 - Take the above series and loop it checking value == 8871\n",
    "(Number of rows in the dataset. Its actually 8872 but the counts start from 0 so value is down by 1)\n",
    "For now printing number of colomns.\n",
    "\"\"\"\n",
    "indexes = data.isnull().sum()\n",
    "null_names = []\n",
    "num = 1\n",
    "for index,value in indexes.items():\n",
    "    if value == 8871:\n",
    "        num +=1\n",
    "        null_names.append(index)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 22% of missing data is been contributed by these colomns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "# Method 2 - Doing the same as above - Getting names of missing colomns\n",
    "null_columns=data.columns[data.isnull().any()]\n",
    "print(null_columns.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the colomn names mentioned are having NaN in their entire colomns. We can do same thing to find the polar opposite in method one- find colomns with no values missing. Best way for now(without digging much into the datatype of colomn values,fill it with \"Nan\") and drop colomns which have no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns using both the lists is ok(null_names or null_columns)\n",
    "data=data.drop(data[null_names],axis=1)\n",
    "data= data.replace([' '], np.nan) # or can use pandas.fillna to do the work\n",
    "#data= data.replace(r'^\\s+$', np.nan, regex=True) - using regrex to search blank entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>race</th>\n",
       "      <th>language</th>\n",
       "      <th>live_us</th>\n",
       "      <th>parents</th>\n",
       "      <th>home</th>\n",
       "      <th>...</th>\n",
       "      <th>music</th>\n",
       "      <th>stu_gov</th>\n",
       "      <th>com_ser</th>\n",
       "      <th>com_groups</th>\n",
       "      <th>hrs_work</th>\n",
       "      <th>transskl</th>\n",
       "      <th>rx_use2</th>\n",
       "      <th>SCHOOL</th>\n",
       "      <th>SURLANG</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>SH14</td>\n",
       "      <td>3040</td>\n",
       "      <td>18 years old or older</td>\n",
       "      <td>Female</td>\n",
       "      <td>Junior - 11th</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Between 1-3 years</td>\n",
       "      <td>My mother only</td>\n",
       "      <td>A house/condo/apartment owned/rented by my par...</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>More than 30 hours</td>\n",
       "      <td>Walk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somerville HS</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>SH04</td>\n",
       "      <td>4019</td>\n",
       "      <td>18 years old or older</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sophomore - 10th</td>\n",
       "      <td>White</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A house/condo/apartment owned/rented by my par...</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Take a bus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survey    id                    age  gender             grade  \\\n",
       "2082   SH14  3040  18 years old or older  Female     Junior - 11th   \n",
       "6537   SH04  4019  18 years old or older    Male  Sophomore - 10th   \n",
       "\n",
       "                    race language            live_us         parents  \\\n",
       "2082  Hispanic or Latino  Spanish  Between 1-3 years  My mother only   \n",
       "6537               White  English                NaN             NaN   \n",
       "\n",
       "                                                   home  ...  music stu_gov  \\\n",
       "2082  A house/condo/apartment owned/rented by my par...  ...     No      No   \n",
       "6537  A house/condo/apartment owned/rented by my par...  ...     No     Yes   \n",
       "\n",
       "     com_ser com_groups            hrs_work    transskl rx_use2  \\\n",
       "2082      No         No  More than 30 hours        Walk     NaN   \n",
       "6537      No        NaN                None  Take a bus     NaN   \n",
       "\n",
       "             SCHOOL  SURLANG  year  \n",
       "2082  Somerville HS  Spanish  2014  \n",
       "6537            NaN      NaN  2004  \n",
       "\n",
       "[2 rows x 168 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question 2: Is the data consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think data is consistent.To check data to be consistent,\n",
    "         check for duplicate entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8871\n"
     ]
    }
   ],
   "source": [
    "data[data.duplicated(keep=False)]\n",
    "print(len(data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we can see, there aren't any duplicates hence its consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question 3 : Is the data bugs free?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What i understand of \"bug\" in data is data collected isn't proper.For instance the 'Id' and 'survey' field are inter-related. but there are many rows where neither of them are given. Assuming that both colomns are needed, Its a problem to figure out what/how to fill those places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1466\n"
     ]
    }
   ],
   "source": [
    "# Just id colomn has around 16% of data missing\n",
    "print(data[\"id\"].isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per data itself, we can't feed it to any machine learning algorithms. As the data contains many categorical colomns, we can see for any \"outliers\" in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parents\n",
       "Another relative (like a grandparent, aunt/uncle)     226\n",
       "Foster parent(s)                                       16\n",
       "My father and a step-parent                            76\n",
       "My father only                                        152\n",
       "My mother and a step-parent                           389\n",
       "My mother and my father                              2873\n",
       "My mother only                                       1130\n",
       "Someone else not on this list                          92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('parents').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up all the entries, It has nearly half of the entry missing!. Assuming that problem solved, the data is heavly biased to one catagory. Data isnt spread evenly.If this is a training-dataset and If this colomn was my label/target/prediction/output of the model, the output will be biased to one outcome itself as dataset itself has biased targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this imbalance is neglected, then we can say the entries which have negligible contributions considered as outliers which throws off the accuracy of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Conclusion</h3>\n",
    "1. If Data is missing, find a way to re-fill it or drop the colomn. \n",
    "2. If Data is having repeated entries, remove them.\n",
    "3. if Data has multiple colomns with contiuous values, try to get them under a standard scale and normalize the data if needed\n",
    "4. If Data is imbalanced,due to a particular colomn , try alternate ways to balance it our drop the colomn.\n",
    "\n",
    "\n",
    "All the above mentioned steps wil improve the integrity of the dataset. This pre-processing is required for all data and the process of doing it depends on the data. Hope I have answered the question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
